> 先了解一些

> 频率/光谱误差(frequency bias)：  
>一方面在样本密度（相对于频率）分布均匀，网络会更快地学习到低频特征，而学习到高频特征则需要更多的训练时长；另一方面当样本集中分布在高频特征区域时，网络极有可能优先学习出高频特征（即优先学习得到样本密度高的区域的特征）。这里要注意的是低频信号的泛化性要更强。

>NeRF学习过程中高低频信号分别是什么？  
>从 geometry 的角度出发，低频信号是目标场景的轮廓（比如球形之于苹果），高频信号则是轮廓上细微的形状（比如苹果的柄和两端的凹陷）；  
>从 appearance 的角度出发，低频信号是 diffuse，高频信号就是 specular。

# 要解决的问题
用少量视角的图片进行神经渲染，从频率的角度解决少量视图进行神经渲染的问题，具体来说，提出两个正则化方法，分别是频率正则化和遮挡正则化。

# 具体实现
### 一、Frequency Regularization(频率正则化)
这里仅针对 geometry 部分，因为 NeRF degeneration 主要表现是 floater（类似云雾的效果），这显然是因为 geometry 没优化好导致的。而正如上面提到的 geometry 的低频信号对应的是目标场景的轮廓，而轮廓信息恰恰需要多视角提供；而高频信息往往只出现在少数几个视角里（因为越细致的形状越难反映在多视角中）。因此给定少视角意味着低频信号的样本密度低，同时由于NeRF采用了 Positional Encoding （包含了高频信号的基函数），少视角中包含的高频信号（细致的形状）反而会更容易优化出来，因为较高频率的映射能够加快高频分量的收敛速度，然而，高频上的过快收敛阻碍了NeRF探索低频信息，并使NeRF明显偏向不期望的高频伪像，因此，我们假设高频成分是在少数镜头神经渲染中观察到模糊图像的主要原因。  
而作者为了解决这一问题，作者提出了一个 Positional Encoding 的退火策略：  
![Frequency-Regularization](https://github.com/gjgjgjfff/Nerf_Learn/blob/main/img/FreeNerf/Frequency-Regularization.png)  
上面这个公式比较抽象，可以看下面这个代码，简单来说就是从没有位置编码的原始输入开始，随着训练的进行（训练步长t的增加），逐渐开放 Positional Encoding 中高频信号的参与。这样一来就强迫 NeRF 在训练的早期优化低频部分，从而实现更好的泛化性能。  
![Frequency-Regularization-code](https://github.com/gjgjgjfff/Nerf_Learn/blob/main/img/FreeNerf/Frequency-Regularization-code.png)  
### 二、Occlusion Regularization(遮挡正则化)
