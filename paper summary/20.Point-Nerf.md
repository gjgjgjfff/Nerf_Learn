# 要解决的问题
NeRF系列针对每个场景从头开始重建太过耗费时间，并且还对很多大片的空旷区域进行了不必要的采样。作者观察到基于学习的multi-view stereo（MVS）可以快速地重建一些场景，所以用基于MVS的方法得到神经点云来指导NeRF，大大加快重建速度。

# 具体实现
Point-Nerf可以分为两个部分，生成初始的基于点的辐射场(Generating initial point-based radiance fields)和优化基于点的辐射场(Optimizing point-based radiance fields)
## 生成初始的基于点的辐射场(Generating initial point-based radiance fields)
### 一、点位置和置信度
对于给定的不同视角的图片，首先用MVSnet生成的深度图构建出点云 ${p_i}$ ，然后在前面构成的深度概率体上三维线性地采样来获得每个点代表场景表面的置信度 ${\gamma _i}$ ，可以公式化为：  
![Point-location-and-confidence](https://github.com/gjgjgjfff/Nerf_Learn/blob/main/img/Point-Nerf/Point-location-and-confidence.png)  
 ${I_q}$ 和 ${\Phi _q}$  
 
 $q$  的输入图像和相机参数， ${I_{q1}}$ 和 ${\Phi _{q1}}$ ...代表MVS重建中使用的附加相邻视图，在大多数情况下，使用两个附加视图。
### 二、点特征
我们使用2DCNN ${G_f}$ 从每个图像 ${I_q}$ 中提取图像特征图，这些特征图与来自 ${G_{p,\gamma }}$ 的深度预测对齐，并用于直接预测每点特征 ${f_i}$，可以公式化为：  
![Point-feature](https://github.com/gjgjgjfff/Nerf_Learn/blob/main/img/Point-Nerf/Point-feature.png)  
论文中用具有三个下采样层的VGG网络构成 ${G_f}$ ，将不同分辨率的中间特征组合为 ${f_i}$ 。  
通过以上步骤就可以生成神经点云，从这个点云中可以回归出辐射场：  
![Point-location-and-confidence](https://github.com/gjgjgjfff/Nerf_Learn/blob/main/img/Point-Nerf/Point-location-and-confidence.png)  
