# 要解决的问题
* 本文主要研究的问题是如何从一个稀疏(少量)的输入视图集中合成这个场景的新视图，虽然NeRF可以渲染非常逼真的新视图，但它通常是不切实际的，因为它需要大量的位姿图像和冗长的场景优化，所以本文研究如何从少量的输入图片中预测场景。
# 具体实现
Nerf不使用任何图像特征，而pixelNerf将与每个像素对齐的空间特征作为输入(即先用卷积网络获得图像特征，将该特征加到Nerf网络的输入中)，以学习场景的先验知识，从而之后用少量的输入视图就可以合成新视图。  
本文提出的模型由两个部分组成：一个完全卷积的图像编码器E(将输入图像编码为像素对齐的特征网格)和一个NeRF网络f(给定一个空间位置及其对应的编码特征，输出颜色和密度)。
### 一、单图像输入的pixelNerf
对于相机光线上的点x，将x投影到图像坐标 $\pi (x)$，然后在像素点上进行双线性插值来提取相应的图像特征向量 $W(\pi (x))$，然后将该特征与(x,d)一起送入Nerf网络中得到RGB和体密度 $\sigma $。
### 二、合并多个视图
![Incorporating-Multiple-Views](https://github.com/gjgjgjfff/Nerf_Learn/blob/main/img/pixelNerf/Incorporating-Multiple-Views.png)
